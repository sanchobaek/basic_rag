import os
from dotenv import load_dotenv  # í™˜ê²½ë³€ìˆ˜ ë¡œë”©ì„ ìœ„í•œ ëª¨ë“ˆ
from langchain_upstage import UpstageDocumentParseLoader  # PDF ë¬¸ì„œ íŒŒì‹±ì„ ìœ„í•œ Upstage AI ë¡œë”
from langchain.text_splitter import RecursiveCharacterTextSplitter  # ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” í…ìŠ¤íŠ¸ ë¶„í• ê¸°
from langchain_huggingface import HuggingFaceEmbeddings  # í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ì„ë² ë”© ëª¨ë¸
from langchain_postgres import PGVector  # PostgreSQL ê¸°ë°˜ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
import traceback #ì—ëŸ¬ ì¶”ì  ë„êµ¬

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (API í‚¤, DB ì—°ê²°ì •ë³´ ë“±)
load_dotenv()

# Upstage AI API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì™€ì„œ ì„¤ì •
os.environ["UPSTAGE_API_KEY"] = os.getenv("UPSTAGE_API_KEY", "")

# PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° URLê³¼ ì»¬ë ‰ì…˜ëª…ì„ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
DATABASE_URL = os.getenv("DATABASE_URL")  # PostgreSQL ì—°ê²° ë¬¸ìì—´
COLLECTION_NAME = os.getenv("COLLECTION_NAME", "documents")  # ë²¡í„° ë°ì´í„°ë¥¼ ì €ì¥í•  í…Œì´ë¸”ëª…


def load_and_process_documents(file_path: str = "./test_modified.pdf"):
    print("ë¬¸ì„œ ë¡œë”© ì¤‘...")
      
    loader = UpstageDocumentParseLoader( 
        file_path,
        split="page",   #í˜ì´ì§€ ë‹¨ìœ„ë¡œ ë¶„í• 
        output_format="markdown", #markdown í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
        ocr="auto", #ocr ìë™ ì ìš© 
        coordinates=True, #í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì •ë³´ í¬í•¨
    )
    docs = loader.load()  # ë¬¸ì„œ ë¡œë”© ì‹¤í–‰
    print(f"ë¬¸ì„œ ë¡œë”© ì™„ë£Œ: {len(docs)}ê°œ í˜ì´ì§€") # ë¬¸ì„œì˜ ëª‡ ê°œ í˜ì´ì§€ê°€ ë¡œë”©ë˜ì–´ìˆëŠ” í”„ë¦°íŠ¸

    
    print("ğŸ”ª ë¬¸ì„œ ì²­í‚¹ ì¤‘...") #ë¡œë”©ëœ ë¬¸ì„œë¥¼ ë” ì‘ì€ ì²­í¬ë¡œ ë¶„í• 
    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300) #ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜, ì²­í¬ ê°„ ì¤‘ë³µë˜ëŠ” ë¬¸ì ìˆ˜
    docs_splitter = splitter.split_documents(docs) #ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì„œ docs_splitterì— ì €ì¥
    print(f"âœ… ì²­í‚¹ ì™„ë£Œ: {len(docs_splitter)}ê°œ ì²­í¬") #ì²­í¬ ê¸¸ì´ í™•ì¸ 

    return docs_splitter #ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ´ìœ¼ë‹ˆ ì´ ê²°ê³¼ë¥¼ ë‹¤ìŒ ì‘ì—…(mainì—ì„œ ì‚¬ìš©)ì— ì‚¬ìš©í•˜ì„¸ìš”~


def initialize_embeddings():    # HuggingFaceì—ì„œ ì œê³µí•˜ëŠ” ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    print("ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    hf_embeddings = HuggingFaceEmbeddings(
        model_name="intfloat/multilingual-e5-large-instruct", #í•œêµ­ì–´ë¥¼ í¬í•¨í•œ ë‹¤êµ­ì–´ë¥¼ ì§€ì›í•˜ëŠ” E5 ëª¨ë¸ 
        model_kwargs={"device": "cpu"}, #cpuì—ì„œ ì‹¤í–‰(gpuê°€ ì—†ê¸°ë•Œë¬¸, ì„ë² ë”© ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¼.)
        encode_kwargs={"normalize_embeddings": True}, #ë²¡í„° ì •ê·œí™”ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°ì— ìµœì 
    )
    
    print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    return hf_embeddings #ì„ë² ë”©í•œ ê²°ê³¼ë¥¼ ë‹¤ìŒ ì‘ì—…(mainì—ì„œ ì‚¬ìš©)ì— ì‚¬ìš©í•˜ì„¸ìš”


def create_vector_store(docs_splitter, embeddings):
    print("ğŸ—„ï¸ PostgreSQL/PGVector ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
    
    # ê¸°ì¡´ ì»¬ë ‰ì…˜ í™•ì¸ ë° ì—°ê²°
    vectorstore = PGVector(
        embeddings=embeddings,
        connection_string=DATABASE_URL,
        collection_name=COLLECTION_NAME,
    )
    
    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì¬í•™ìŠµ ì‹œ ì¤‘ë³µ ë°©ì§€)
    print("ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘...")
    vectorstore.delete_collection()
    
    #ì‹¤ì œ ë°ì´í„° ì €ì¥ ë‹´ë‹¹
    vectorstore = PGVector.from_documents(
        documents=docs_splitter,      # ì²­í‚¹ëœ ë¬¸ì„œë“¤ì„
        embedding=embeddings,         # ì„ë² ë”© ëª¨ë¸ë¡œ ë²¡í„°í™”í•´ì„œ
        connection_string=DATABASE_URL,
        collection_name=COLLECTION_NAME,
    )                                # PostgreSQLì— ì €ì¥
    
    print("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")
    return vectorstore


def main():
    """
    ì „ì²´ ë°ì´í„° ì¸ì œìŠ¤ì²œ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    PDF ë¬¸ì„œ â†’ ì²­í‚¹ â†’ ì„ë² ë”© â†’ PostgreSQL ì €ì¥ê¹Œì§€ì˜ ì „ ê³¼ì •ì„ ìˆ˜í–‰
    """
    try:
        print("ğŸš€ ë°ì´í„° ì¸ì œìŠ¤ì²œ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print(f"ğŸ“ ë°ì´í„°ë² ì´ìŠ¤: {DATABASE_URL}")
        print(f"ğŸ“ ì»¬ë ‰ì…˜: {COLLECTION_NAME}")
        print("-" * 50)
        
        # 1ë‹¨ê³„: PDF ë¬¸ì„œë¥¼ ë¡œë”©í•˜ê³  ì‘ì€ ì²­í¬ë¡œ ë¶„í• 
        docs_splitter = load_and_process_documents()
        
        # 2ë‹¨ê³„: í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•  ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        embeddings = initialize_embeddings()
        
        # 3ë‹¨ê³„: PostgreSQL/PGVector ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ë¬¸ì„œ ë°ì´í„° ì €ì¥
        vectorstore = create_vector_store(docs_splitter, embeddings)
        
        # 4ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸
        print("ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì¤‘...")
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})  # ìƒìœ„ 3ê°œ ê²°ê³¼ ë°˜í™˜
        # test_results = retriever.invoke("ì•„ì£¼ëŒ€í•™êµ")  # "ì•„ì£¼ëŒ€í•™êµ" í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        # print(f"âœ… ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(test_results)}ê°œ ê²°ê³¼")
        
        print("-" * 50)
        print("ğŸ‰ ë°ì´í„° ì¸ì œìŠ¤ì²œ ì™„ë£Œ!")
        print("ì´ì œ RAG ì„œë¹„ìŠ¤ì—ì„œ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì¸ì œìŠ¤ì²œ ì‹¤íŒ¨: {e}")
        
        traceback.print_exc()  # ìƒì„¸í•œ ì—ëŸ¬ ì •ë³´ ì¶œë ¥


# ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ main() í•¨ìˆ˜ í˜¸ì¶œ
if __name__ == "__main__":
    main()