{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2004ba21",
   "metadata": {},
   "source": [
    "RAG - Loader(UpstageDocumentParseLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import UpstageDocumentParseLoader\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# os.environ[\"UPSTAGE_API_KEY\"] = \"\"\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "file_path = \"./test_modified.pdf\"\n",
    "\n",
    "loader = UpstageDocumentParseLoader(\n",
    "    file_path,\n",
    "    split=\"page\",  # 페이지별로 분할\n",
    "    output_format=\"markdown\",  # 텍스트 형태로 출력\n",
    "    ocr=\"auto\",  # 자동 OCR 사용\n",
    "    coordinates=True,  # 좌표 정보 포함\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59fa30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(docs[21].page_content)\n",
    "# print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d44f9b7",
   "metadata": {},
   "source": [
    "Rag - Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdbda95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#  문서 자르기 (AI가 읽기 쉬운 크기로 쪼개기)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)\n",
    "\n",
    "# 문서 분할 실행\n",
    "docs_splitter = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3aab1",
   "metadata": {},
   "source": [
    "Rag - Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aeb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# 기존 임베딩 그대로 사용\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-large-instruct\",\n",
    "    model_kwargs={\"device\": \"mps\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52858f3",
   "metadata": {},
   "source": [
    "Rag - Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG - Vector Store\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=docs_splitter,\n",
    "    embedding=hf_embeddings,  # 커스텀 임베딩 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647a517",
   "metadata": {},
   "source": [
    "Rag - retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a3da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG - retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5},\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",  # 유사도 검색\n",
    "    search_kwargs={\"k\": 5},  # 상위 5개 결과 반환\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14cfc99",
   "metadata": {},
   "source": [
    "Rag - Formatting / Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30217fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import hub\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ea006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 설정 (스트리밍 활성화)\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0, streaming=True)\n",
    "\n",
    "\n",
    "# 간단한 리스트 기반 히스토리 관리\n",
    "chat_history_list = []\n",
    "\n",
    "\n",
    "def add_to_history(role, message):\n",
    "    \"\"\"히스토리에 메시지 추가\"\"\"\n",
    "    chat_history_list.append(f\"{role}: {message}\")\n",
    "\n",
    "    # 최근 6개 메시지만 유지 (3턴)\n",
    "    if len(chat_history_list) > 6:\n",
    "        chat_history_list.pop(0)\n",
    "\n",
    "\n",
    "def get_chat_history(x):\n",
    "    \"\"\"현재 히스토리를 문자열로 반환\"\"\"\n",
    "    if not chat_history_list:\n",
    "        return \"이전 대화 없음\"\n",
    "    return \"\\n\".join(chat_history_list)\n",
    "\n",
    "\n",
    "def clear_history():\n",
    "    \"\"\"히스토리 초기화\"\"\"\n",
    "    chat_history_list.clear()\n",
    "\n",
    "\n",
    "# 문서 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# 일반 함수 정의\n",
    "def extract_input(data):\n",
    "    \"\"\"딕셔너리에서 input 키의 값을 추출하는 함수\"\"\"\n",
    "    return data[\"input\"]\n",
    "\n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"너는 친절한 한국어 AI 비서야. \n",
    "        제공된 문서 내용(context)과 이전 대화 내용을 참고해서 질문에 답해.\n",
    "        반드시 한국어로만 대답하고, 문서에 없는 내용은 대답하지마.\n",
    "        \n",
    "        참고 문서:\n",
    "        {context}\n",
    "        \n",
    "        이전 대화:\n",
    "        {chat_history}\n",
    "        \"\"\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 체인 구성\n",
    "rag_multiturn_chain = (\n",
    "    {\n",
    "        # 1단계: 사용자 질문으로 관련 문서 검색 후 포맷팅\n",
    "        \"context\": extract_input | retriever | format_docs, \n",
    "        # 2단계: 원본 질문 전달   \n",
    "        \"input\": extract_input, \n",
    "        # 3단계: 대화 히스토리 가져오기\n",
    "        \"chat_history\": get_chat_history,\n",
    "    }\n",
    "    | prompt # 4단계: 프롬프트에 모든 정보 결합\n",
    "    | llm # 5단계: LLM이 답변 생성\n",
    "    | StrOutputParser() # 6단계: 문자열로 출력 파싱\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66854ea8",
   "metadata": {},
   "source": [
    "Rag - Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_rag_multiturn_response(user_input):\n",
    "    \"\"\"RAG + 멀티턴 대화를 스트리밍으로 처리    \"\"\"\n",
    "\n",
    "    print(f\"🙋 사용자: {user_input}\")\n",
    "    print(\"🤖 AI: \", end=\"\", flush=True)\n",
    "\n",
    "    response = \"\"\n",
    "\n",
    "    try:\n",
    "        for chunk in rag_multiturn_chain.stream({\"input\": user_input}):\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "            response += chunk\n",
    "\n",
    "        print()  # 줄바꿈\n",
    "\n",
    "        # 히스토리에 대화 추가\n",
    "        add_to_history(\"사용자\", user_input)\n",
    "        add_to_history(\"AI\", response)\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"오류 발생: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        print(f\"상세 오류: {type(e).__name__}: {e}\")\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba8109",
   "metadata": {},
   "source": [
    "Rag - Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6c526936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG - Streaming\n",
    "def interactive_chat():\n",
    "    \"\"\"대화형 채팅 인터페이스\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🤖 RAG 챗봇 시작\")\n",
    "    print(\"💡 '종료' 입력 시 대화를 끝냅니다.\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\"\\n🙋 사용자: \").strip()\n",
    "\n",
    "                if not user_input:\n",
    "                    print(\"❗ 메시지를 입력해주세요.\")\n",
    "                    continue\n",
    "\n",
    "                if user_input.lower() == \"종료\":\n",
    "                    print(\"👋 채팅을 종료합니다!\")\n",
    "                    break\n",
    "\n",
    "                stream_rag_multiturn_response(user_input)\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n채팅을 종료합니다!\")\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        clear_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413cf36c",
   "metadata": {},
   "source": [
    "Rag - Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae3c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG - QnA\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_chat()  # 대화형 모드 실행"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
