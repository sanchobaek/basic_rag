{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bcab1d9",
   "metadata": {},
   "source": [
    "라이브러리 임포트\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed375125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Optional, Literal, List, Dict, Any\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "import enum\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import uuid\n",
    "\n",
    "# LangChain 및 기타 필요한 라이브러리 임포트\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "\n",
    "# LangGraph 관련 임포트\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 기존 RAG 코드에서 가져온 컴포넌트\n",
    "from langchain_upstage import UpstageDocumentParseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 랭퓨즈\n",
    "from langfuse import Langfuse, get_client\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# 스트리밍\n",
    "import asyncio\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 서치 툴 travily\n",
    "import getpass\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import json\n",
    "from langgraph.prebuilt import tools_condition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a8265c",
   "metadata": {},
   "source": [
    "설정 및 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edac3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env 파일 로드 (필요한 경우)\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087a03a",
   "metadata": {},
   "source": [
    "유틸리티 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32285bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format documents function\n",
    "def format_docs(docs):\n",
    "    \"\"\"Format documents into a single string\"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# 1. initialize_rag_components 함수 수정 - Sonnet 4만 사용\n",
    "def initialize_rag_components(file_path: str = \"./test_modified.pdf\"):\n",
    "    \"\"\"Initialize all components for RAG\"\"\"\n",
    "    print(\"문서 로딩 중...\")\n",
    "\n",
    "    # Document loading\n",
    "    loader = UpstageDocumentParseLoader(\n",
    "        file_path,\n",
    "        split=\"page\",\n",
    "        output_format=\"markdown\",\n",
    "        ocr=\"auto\",\n",
    "        coordinates=True,\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    print(f\"문서 로딩 완료: {len(docs)} 페이지\")\n",
    "\n",
    "    # Document chunking\n",
    "    print(\"문서 청킹 중...\")\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)\n",
    "    docs_splitter = splitter.split_documents(docs)\n",
    "    print(f\"청킹 완료: {len(docs_splitter)} 청크\")\n",
    "\n",
    "    # Embedding model\n",
    "    print(\"임베딩 모델 로딩 중...\")\n",
    "    device = \"cpu\"  # 기본값으로 CPU 사용\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda\"\n",
    "        elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "            device = \"mps\"\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    print(f\"사용 중인 디바이스: {device}\")\n",
    "\n",
    "    hf_embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"intfloat/multilingual-e5-large-instruct\",\n",
    "        model_kwargs={\"device\": device},\n",
    "        encode_kwargs={\"normalize_embeddings\": True},\n",
    "    )\n",
    "\n",
    "    # Vector store\n",
    "    print(\"벡터 스토어 생성 중...\")\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=docs_splitter,\n",
    "        embedding=hf_embeddings,\n",
    "    )\n",
    "    print(\"벡터 스토어 생성 완료\")\n",
    "\n",
    "    # Retriever\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5},\n",
    "    )\n",
    "\n",
    "    # Sonnet 4 LLM - 모든 작업용\n",
    "    print(\"🚀 Sonnet 4 LLM 초기화 중...\")\n",
    "    sonnet_llm = ChatAnthropic(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        temperature=0,\n",
    "        streaming=True,\n",
    "    )\n",
    "\n",
    "    #웹 검색 툴과 바인딩\n",
    "    tools = [tavily_web_search]\n",
    "    sonnet_llm_with_tools = sonnet_llm.bind_tools(tools)\n",
    "    \n",
    "    print(\"✅ Sonnet 4 LLM 초기화 완료!\")\n",
    "\n",
    "    return {\n",
    "        \"retriever\": retriever,\n",
    "        \"llm\": sonnet_llm,                    # 모든 작업용 Sonnet 4\n",
    "        \"llm_with_tools\": sonnet_llm_with_tools,  # 웹 검색용 Sonnet 4\n",
    "        \"tools\": tools\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e1f53b",
   "metadata": {},
   "source": [
    "모델 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d55733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 웹 검색 툴 함수 업데이트 완료!\n"
     ]
    }
   ],
   "source": [
    "# Define categories for query classification\n",
    "class Category(enum.Enum):\n",
    "    DOCUMENT = \"document\"  # 문서 관련 질문\n",
    "    GENERAL =\"general\"\n",
    "\n",
    "# Pydantic model for structured output\n",
    "class QueryClassification(BaseModel):\n",
    "    \"\"\"사용자 쿼리 분류 모델\"\"\"\n",
    "\n",
    "    category: Category = Field(\n",
    "        description=\"쿼리를 카테고리화 하세요. DOCUMENT(문서 관련 질문) / GENERAL(일반적인 질문) 중에 하나로 구분하세요.\"\n",
    "    )\n",
    "    reasoning: str = Field(description=\"왜 이 카테고리를 선택했는지 설명하세요.\")\n",
    "\n",
    "\n",
    "# Define the state structure\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    context: List[str]\n",
    "    category: Optional[str]\n",
    "    transformed_query: Optional[str]  # 🆕 변환된 쿼리 저장\n",
    "\n",
    "\n",
    "# 2. setup_tool 함수 단순화\n",
    "def setup_tool():\n",
    "    \"\"\"웹 검색 툴 노드 생성\"\"\"\n",
    "    global rag_components\n",
    "    \n",
    "    # ToolNode 생성 (이미 rag_components에 tools가 있음)\n",
    "    tool_node = ToolNode(rag_components[\"tools\"])\n",
    "    \n",
    "    print(\"✅ 웹 검색 툴 설정 완료!\")\n",
    "    return tool_node\n",
    "\n",
    "# 3. router 함수 수정 - Sonnet 4 사용\n",
    "def router(state: State) -> Dict[str, Any]:\n",
    "    \"\"\"사용자 쿼리를 카테고리로 분류하는 라우터 - Sonnet 4 사용\"\"\"\n",
    "    print(\"🚀 쿼리 분류 중 (Sonnet 4)...\")\n",
    "\n",
    "    # Get the most recent user message\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "\n",
    "    # Create the router input\n",
    "    router_input = f\"\"\"\n",
    "    다음 사용자 쿼리를 분석하고 카테고리를 결정하세요.\n",
    "    카테고리:\n",
    "    - document: 문서 내용에 관한 질문 (예: \"아주대학교에 대해 알려줘\", \"이 문서에서 중요한 내용은?\")\n",
    "    - general: 일반적인 질문으로, 문서와 관련이 없음 (예: \"오늘 날씨 어때?\", \"파이썬이란?\")\n",
    "    \n",
    "    쿼리: {user_message}\n",
    "    \"\"\"\n",
    "\n",
    "    # Sonnet 4 LLM 사용\n",
    "    llm = rag_components[\"llm\"]\n",
    "\n",
    "    # Structured output with the classification model\n",
    "    structured_llm = llm.with_structured_output(QueryClassification)\n",
    "\n",
    "    # Get classification\n",
    "    classification = structured_llm.invoke(router_input)\n",
    "\n",
    "    category = classification.category.value\n",
    "    print(f\"분류 결과: {category} (이유: {classification.reasoning}) - Sonnet 4\")\n",
    "\n",
    "    return {\"category\": category}\n",
    "\n",
    "\n",
    "# Conditional routing function\n",
    "def route_by_category(state: State) -> Literal[\"document_qa\", \"general_qa\"]:\n",
    "    \"\"\"카테고리에 기반하여 다음 노드를 결정\"\"\"\n",
    "    category = state.get(\"category\", \"\").lower()\n",
    "\n",
    "    if category == \"document\":\n",
    "        return \"document_qa\"\n",
    "    elif category == \"general\":\n",
    "        return \"general_qa\"\n",
    "    else:\n",
    "        # 기본값은 일반 질의응답\n",
    "        return \"general_qa\"\n",
    "\n",
    "\n",
    "def query_transform(state: State) -> Dict[str, Any]:\n",
    "    \"\"\"사용자 쿼리를 문서 검색에 최적화된 형태로 변환\"\"\"\n",
    "    print(\"🔄 쿼리 변환 중 (Sonnet 4)...\")\n",
    "    \n",
    "    # 사용자 메시지 추출\n",
    "    user_message = None\n",
    "    for msg in reversed(state[\"messages\"]):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            user_message = msg.content\n",
    "            break\n",
    "    \n",
    "    if not user_message:\n",
    "        return {\"transformed_query\": \"\"}\n",
    "    \n",
    "    # 이전 대화 히스토리 구성\n",
    "    history_messages = state[\"messages\"][:-1]\n",
    "    formatted_history = \"\"\n",
    "    for msg in history_messages:\n",
    "        role = \"사용자\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "        formatted_history += f\"{role}: {msg.content}\\n\"\n",
    "    \n",
    "    # Query Transform 프롬프트\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"너는 문서 검색 쿼리 최적화 전문가야.\n",
    "        사용자의 질문을 분석해서 문서에서 관련 정보를 더 잘 찾을 수 있도록 쿼리를 변환해.\n",
    "        \n",
    "        ## 쿼리 변환 규칙:\n",
    "        1. **핵심 키워드 추출**: 불필요한 단어 제거하고 핵심 단어만 남기기\n",
    "        2. **동의어 확장**: 관련 용어들 추가 (예: \"대학교\" → \"대학교, 대학, 학교\")\n",
    "        3. **검색 최적화**: 문서에서 찾기 쉬운 형태로 변환\n",
    "        4. **컨텍스트 반영**: 이전 대화 맥락을 고려한 쿼리 확장\n",
    "        5. **구체화**: 모호한 표현을 구체적으로 변환\n",
    "        \n",
    "        ## 변환 예시:\n",
    "        - \"아주대에 대해 알려줘\" → \"아주대학교 대학 정보 개요 소개\"\n",
    "        - \"입학 조건이 뭐야?\" → \"입학 조건 지원 자격 요건 모집\"\n",
    "        - \"학과는 어떤게 있어?\" → \"학과 전공 단과대학 계열 전공분야\"\n",
    "        \n",
    "        ## 응답 형식:\n",
    "        쿼리가 어떻게 변경되었는지 알려줘\n",
    "        \n",
    "        이전 대화:\n",
    "        {chat_history}\n",
    "        \"\"\"),\n",
    "        (\"user\", \"원본 쿼리: {original_query}\")\n",
    "    ])\n",
    "    \n",
    "    # Sonnet 4 사용\n",
    "    llm = rag_components[\"llm\"]\n",
    "    \n",
    "    formatted_message = prompt.format_messages(\n",
    "        chat_history=formatted_history,\n",
    "        original_query=user_message\n",
    "    )\n",
    "    \n",
    "    ai_response = llm.invoke(formatted_message)\n",
    "    transformed_query = ai_response.content.strip()\n",
    "    \n",
    "    print(f\"✅ 쿼리 변환 완료: '{user_message}' → '{transformed_query}'\")\n",
    "    \n",
    "    return {\"transformed_query\": transformed_query}\n",
    "\n",
    "# Define LangGraph nodes\n",
    "def retrieve_documents(state: State) -> Dict[str, Any]:\n",
    "    \"\"\"문서에서 관련 내용 검색\"\"\"\n",
    "    print(\"문서 검색 중...\")\n",
    "\n",
    "    # Get the most recent user message\n",
    "    user_message = state[\"messages\"][-1]\n",
    "\n",
    "    # Retrieve documents\n",
    "    retriever = rag_components[\"retriever\"]\n",
    "    docs = retriever.invoke(user_message.content)\n",
    "\n",
    "    # Format documents\n",
    "    formatted_docs = format_docs(docs)\n",
    "    print(f\"검색 완료: {len(docs)} 문서 찾음\")\n",
    "\n",
    "    # Return updated state\n",
    "    return {\"context\": [formatted_docs]}\n",
    "\n",
    "\n",
    "\n",
    "# 1. TavilySearch 인스턴스를 올바르게 생성\n",
    "tavily_search_tool = TavilySearch(\n",
    "    max_results=3,\n",
    "    topic=\"general\"\n",
    ")\n",
    "\n",
    "@tool\n",
    "def tavily_web_search(query: str) -> str:\n",
    "    \"\"\"웹에서 최신 정보를 검색합니다. 뉴스, 날씨, 실시간 데이터 등에 사용하세요.\"\"\"\n",
    "    print(f\"🌐 Tavily 웹 검색 중: {query}\")\n",
    "    \n",
    "    try:\n",
    "        # 이제 tavily_search_tool이 올바른 TavilySearch 인스턴스임\n",
    "        search_results = tavily_search_tool.invoke({\"query\": query})\n",
    "        print(f\"✅ 검색 결과 받음: {type(search_results)}\")\n",
    "        \n",
    "        # 결과 포맷팅\n",
    "        if isinstance(search_results, list):\n",
    "            if len(search_results) == 0:\n",
    "                return \"검색 결과가 없습니다.\"\n",
    "                \n",
    "            formatted_results = []\n",
    "            for i, result in enumerate(search_results[:3]):  # 상위 3개만\n",
    "                title = result.get('title', 'N/A')\n",
    "                content = result.get('content', 'N/A')\n",
    "                url = result.get('url', 'N/A')\n",
    "                \n",
    "                formatted_results.append(f\"\"\"\n",
    "검색 결과 {i+1}:\n",
    "제목: {title}\n",
    "내용: {content[:300] if content != 'N/A' else 'N/A'}...\n",
    "출처: {url}\n",
    "\"\"\")\n",
    "            return \"\\n\".join(formatted_results)\n",
    "        else:\n",
    "            return f\"검색 결과: {str(search_results)[:500]}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = f\"웹 검색 중 오류 발생: {str(e)}\"\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        return error_msg\n",
    "\n",
    "print(\"✅ 웹 검색 툴 함수 업데이트 완료!\")\n",
    "\n",
    "# 웹 검색 툴을 기존 LLM에 바인딩\n",
    "# def bind_web_search_to_llm():\n",
    "#     \"\"\"기존 LLM에 웹 검색 툴을 바인딩합니다.\"\"\"\n",
    "#     global rag_components\n",
    "\n",
    "#     # 웹 검색 툴 리스트\n",
    "#     tool = [tavily_web_search]\n",
    "\n",
    "#     # 기존 LLM에 툴 바인딩\n",
    "#     llm = rag_components[\"llm\"]\n",
    "#     llm_with_tools = llm.bind_tools(tool)\n",
    "\n",
    "#     # rag_components 업데이트\n",
    "#     rag_components[\"llm_with_tools\"] = llm_with_tools\n",
    "#     rag_components[\"tool\"] = tool\n",
    "\n",
    "#     print(\"✅ 기존 LLM에 웹 검색 툴 바인딩 완료!\")\n",
    "#     return llm_with_tools #여기서 rutune 어떻게 사용되나???????????????????????????????????????????????\n",
    "\n",
    "# def setup_dual_model_system():\n",
    "#     \"\"\"툴 사용시와 일반 응답시 다른 모델을 사용하도록 설정\"\"\"\n",
    "#     print(\"🔧 듀얼 모델 시스템 설정 중...\")\n",
    "    \n",
    "#     # 1. 기본 모델 (Haiku 3) - 빠른 응답용\n",
    "#     base_llm = ChatAnthropic(\n",
    "#         model=\"claude-3-haiku-20240307\",\n",
    "#         temperature=0,\n",
    "#         streaming=True,\n",
    "#     )\n",
    "    \n",
    "#     # 2. 고성능 모델 (Sonnet 4) - 툴 사용시\n",
    "#     advanced_llm = ChatAnthropic(\n",
    "#         model=\"claude-sonnet-4-20250514\",  # 🚀 Sonnet 4 사용\n",
    "#         temperature=0,\n",
    "#         streaming=True,\n",
    "#     )\n",
    "    \n",
    "#     # 3. 툴이 바인딩된 고성능 모델\n",
    "#     tools = [tavily_web_search]\n",
    "#     advanced_llm_with_tools = advanced_llm.bind_tools(tools)\n",
    "    \n",
    "#     # 4. 컴포넌트 반환\n",
    "#     components = {\n",
    "#         \"llm\": base_llm,                           # 기본 모델 (Haiku 3)\n",
    "#         \"advanced_llm\": advanced_llm,              # 고성능 모델 (Sonnet 4)\n",
    "#         \"llm_with_tools\": advanced_llm_with_tools, # 툴 바인딩된 고성능 모델\n",
    "#         \"tools\": tools\n",
    "#     }\n",
    "    \n",
    "#     print(\"✅ 듀얼 모델 시스템 설정 완료!\")\n",
    "#     print(\"📊 기본 응답: Claude Haiku 3 (빠름)\")\n",
    "#     print(\"🧠 툴 사용시: Claude Sonnet 4 (고성능)\")\n",
    "    \n",
    "#     return components\n",
    "\n",
    " #4. document_qa 함수 수정 - Sonnet 4 사용\n",
    "def document_qa(state: State) -> Dict[str, Any]:\n",
    "    \"\"\"문서 기반 질의응답 - Sonnet 4 사용\"\"\"\n",
    "    print(\"🚀 문서 기반 응답 생성 중 (Sonnet 4)...\")\n",
    "    context = state[\"context\"][0] if state[\"context\"] else \"문서 정보 없음\"\n",
    "    \n",
    "    # Get user message\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "\n",
    "    # 이전 대화들은 별도로 히스토리 구성\n",
    "    history_messages = state[\"messages\"][:-1]\n",
    "    formatted_history = \"\"\n",
    "    for msg in history_messages:\n",
    "        role = \"사용자\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "        formatted_history += f\"{role}: {msg.content}\\n\"\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"너는 친절한 한국어 AI 비서야. \n",
    "        제공된 문서 내용(context)과 이전 대화 내용을 참고해서 질문에 답해.\n",
    "        반드시 한국어로만 대답하고, 문서에 없는 내용은 대답하지 말고 모른다고 해.\n",
    "        \n",
    "        참고 문서:\n",
    "        {context}\n",
    "        \n",
    "        이전 대화:\n",
    "        {chat_history}\n",
    "        \"\"\"),\n",
    "        (\"user\", \"{user_input}\"),\n",
    "    ])\n",
    "\n",
    "    # Sonnet 4 LLM 사용\n",
    "    llm = rag_components[\"llm\"]\n",
    "\n",
    "    # Create formatted message for LLM\n",
    "    formatted_message = prompt.format_messages(\n",
    "        context=context,\n",
    "        chat_history=formatted_history,\n",
    "        user_input=user_message,\n",
    "    )\n",
    "\n",
    "    # Get response from LLM\n",
    "    ai_response = llm.invoke(formatted_message)\n",
    "    response_content = ai_response.content\n",
    "    print(\"✅ 문서 기반 응답 생성 완료 (Sonnet 4)\")\n",
    "\n",
    "    # Return the assistant message\n",
    "    return {\"messages\": [AIMessage(content=response_content)]}\n",
    "\n",
    "# 5. general_qa 함수 수정 - Sonnet 4 with Tools 사용\n",
    "def general_qa(state: State) -> Dict[str, Any]:\n",
    "    \"\"\"일반 질의응답 - Sonnet 4 with Tools 사용\"\"\"\n",
    "    print(\"🚀 일반 응답 생성 중 (Sonnet 4 + 웹 툴)...\")\n",
    "\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "\n",
    "    # 이전 대화 히스토리 구성\n",
    "    history_messages = state[\"messages\"][:-1]\n",
    "    formatted_history = \"\"\n",
    "    for msg in history_messages:\n",
    "        role = \"사용자\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "        formatted_history += f\"{role}: {msg.content}\\\\n\"\n",
    "\n",
    "    # Sonnet 4 + 툴 사용\n",
    "    llm_with_tools = rag_components[\"llm_with_tools\"]\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"너는 친절한 한국어 AI 비서야. \n",
    "        사용자의 일반적인 질문에 답변해. \n",
    "        만약 최신 정보나 실시간 데이터가 필요하다면 (날씨, 뉴스, 주식 등), tavily_web_search 툴을 사용해서 웹에서 정보를 찾아줘. \n",
    "## ReAct 단계별 처리 방식:\n",
    "\n",
    "**1단계 - 사고 (Thought):** 사용자의 질문을 분석하고 어떤 정보가 필요한지 생각해\n",
    "- 이 질문에 답하기 위해 무엇이 필요한가?\n",
    "- 내가 이미 알고 있는 정보인가, 아니면 최신 정보가 필요한가?\n",
    "- 웹 검색이 필요한가?\n",
    "\n",
    "**2단계 - 행동 (Action):** 필요하다면 적절한 도구를 사용해\n",
    "- 최신 정보나 실시간 데이터가 필요하면: tavily_web_search 툴 사용\n",
    "- 일반 상식으로 답변 가능하면: 바로 답변\n",
    "\n",
    "**3단계 - 관찰 (Observation):** 도구 사용 결과를 분석해\n",
    "- 검색 결과가 질문에 적합한가?\n",
    "- 추가 정보가 필요한가?\n",
    "\n",
    "**4단계 - 답변 (Answer):** 최종 답변을 제공해\n",
    "\n",
    "## 답변 형식:\n",
    "**사고:** [질문 분석 및 필요한 정보 판단]\n",
    "**행동:** [취할 행동 - 웹 검색 또는 직접 답변]\n",
    "**답변:** [사용자에게 제공할 최종 답변]\n",
    "\n",
    "## 웹 검색이 필요한 경우:\n",
    "- 날씨, 뉴스, 주식 가격\n",
    "- 현재 날짜, 시간\n",
    "- 최신 사건, 트렌드\n",
    "- 실시간 데이터\n",
    "\n",
    "## 직접 답변 가능한 경우:\n",
    "- 일반 상식, 역사적 사실\n",
    "- 수학 계산, 언어 번역\n",
    "- 개념 설명, 정의\n",
    "- 기본적인 인사말\n",
    "         \n",
    "\n",
    "## 일반적인 상식으로 답변 가능한 질문은 바로 답변해.\n",
    "        \n",
    "        이전 대화:\n",
    "        {chat_history}\n",
    "        \"\"\"),\n",
    "        (\"user\", \"{user_input}\"),\n",
    "    ])\n",
    "\n",
    "    formatted_message = prompt.format_messages(\n",
    "        chat_history=formatted_history,\n",
    "        user_input=user_message,\n",
    "    )\n",
    "\n",
    "    ai_response = llm_with_tools.invoke(formatted_message)\n",
    "    print(\"✅ 일반 응답 생성 완료 (Sonnet 4)\")\n",
    "\n",
    "    return {\"messages\": [ai_response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f07b3",
   "metadata": {},
   "source": [
    "그래프 노드 함수 및 그래프 빌드 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144be721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 함수들 정의 완료!\n"
     ]
    }
   ],
   "source": [
    "# 1. 먼저 필요한 변수들 정의\n",
    "conversation_history = []  # 전체 대화 히스토리 저장\n",
    "\n",
    "# 2. setup_advanced_llm 함수 추가 - Advanced LLM 설정\n",
    "def setup_advanced_llm():\n",
    "    \"\"\"Advanced LLM (Sonnet 4) with tools 설정\"\"\"\n",
    "    print(\"🧠 Advanced LLM (Sonnet 4) 설정 중...\")\n",
    "    \n",
    "    # Advanced LLM (Sonnet 4) - 웹 검색용\n",
    "    advanced_llm = ChatAnthropic(\n",
    "        model=\"claude-sonnet-4-20250514\",  # 🚀 Sonnet 4 사용\n",
    "        temperature=0,\n",
    "        streaming=True,\n",
    "    )\n",
    "    \n",
    "    # 웹 검색 툴과 바인딩\n",
    "    tools = [tavily_web_search]\n",
    "    advanced_llm_with_tools = advanced_llm.bind_tools(tools)\n",
    "    \n",
    "    print(\"✅ Advanced LLM (Sonnet 4) 설정 완료!\")\n",
    "    return {\n",
    "        \"advanced_llm\": advanced_llm,\n",
    "        \"advanced_llm_with_tools\": advanced_llm_with_tools,\n",
    "        \"tools\": tools\n",
    "    }\n",
    "\n",
    "\n",
    "# 4. Run graph 함수\n",
    "def run_graph(user_input: str):\n",
    "    global conversation_history\n",
    "\n",
    "    # 새로운 사용자 메시지를 히스토리에 추가\n",
    "    user_message = HumanMessage(content=user_input)\n",
    "    conversation_history.append(user_message)\n",
    "\n",
    "    # Create initial state with the user message\n",
    "    initial_state = {\n",
    "        \"messages\": conversation_history,  # 전체 대화 히스토리가 누적된 배열\n",
    "        \"context\": [],\n",
    "        \"category\": None,\n",
    "    }\n",
    "\n",
    "    # Run the graph and get the final state\n",
    "    result = graph.invoke(initial_state)\n",
    "\n",
    "    # Extract the AI response\n",
    "    if \"messages\" in result and len(result[\"messages\"]) > 1:\n",
    "        # Get the assistant message (should be the last one)\n",
    "        ai_msg = result[\"messages\"][-1]\n",
    "        if isinstance(ai_msg, AIMessage):\n",
    "            # AI 응답을 conversation_history에 추가\n",
    "            conversation_history.append(ai_msg)\n",
    "            return ai_msg.content\n",
    "\n",
    "    return \"응답을 생성할 수 없습니다.\"\n",
    "\n",
    "# 5. Interactive chat 함수\n",
    "def interactive_chat():\n",
    "    \"\"\"Interactive chat interface for the RAG system\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🤖 LangGraph 라우팅 RAG 챗봇 시작 (멀티턴 대화 지원)\")\n",
    "    print(\"💡 '종료' 입력 시 대화를 끝냅니다.\")\n",
    "    print(\"💡 '히스토리' 입력 시 현재 대화 히스토리를 확인합니다.\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\"\\n🙋 사용자: \").strip()\n",
    "\n",
    "                if not user_input:\n",
    "                    print(\"❗ 메시지를 입력해주세요.\")\n",
    "                    continue\n",
    "\n",
    "                if user_input.lower() == \"종료\":\n",
    "                    print(\"👋 채팅을 종료합니다!\")\n",
    "                    break\n",
    "\n",
    "                # 히스토리 확인 명령어 추가\n",
    "                if user_input.lower() == \"히스토리\":\n",
    "                    print(\"\\n=== 현재 대화 히스토리 ===\")\n",
    "                    for i, msg in enumerate(conversation_history):\n",
    "                        msg_type = \"사용자\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "                        content = (\n",
    "                            msg.content[:100] + \"...\"\n",
    "                            if len(msg.content) > 100\n",
    "                            else msg.content\n",
    "                        )\n",
    "                        print(f\"{i+1}. {msg_type}: {content}\")\n",
    "                    print(f\"총 {len(conversation_history)}개 메시지\")\n",
    "                    print(\"=\" * 30)\n",
    "                    continue\n",
    "\n",
    "                # Get response\n",
    "                print(\"🤖 AI: \", end=\"\", flush=True)\n",
    "                response = run_graph(user_input)\n",
    "                print(response)\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n👋 채팅을 종료합니다!\")\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"✅ 함수들 정의 완료!\")\n",
    "\n",
    "\n",
    "# Global variables\n",
    "rag_components = None #rag로 이미 만들어진 구성요소들이 담긴 딕셔너리구나\n",
    "graph = None\n",
    "\n",
    "\n",
    "# 6. main 함수 수정\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    global rag_components, graph\n",
    "    \n",
    "    try:\n",
    "        # 1. RAG 컴포넌트 초기화 (Sonnet 4만)\n",
    "        print(\"RAG 컴포넌트 초기화 중...\")\n",
    "        rag_components = initialize_rag_components()\n",
    "        \n",
    "        # 2. 웹 툴 설정\n",
    "        print(\"웹 검색 툴 설정 중...\")\n",
    "        tool_node = setup_tool()\n",
    "        \n",
    "        # 3. 그래프 빌드\n",
    "        print(\"🚀 모든 작업에 Sonnet 4를 사용하는 그래프 구성 중...\")\n",
    "        \n",
    "        graph_builder = StateGraph(State)\n",
    "        \n",
    "        # 노드들 추가\n",
    "        graph_builder.add_node(\"router\", router)          # Sonnet 4\n",
    "        graph_builder.add_node(\"query_transform\", query_transform)  # 쿼리 변환 노드 추가\n",
    "        graph_builder.add_node(\"retrieve\", retrieve_documents)\n",
    "        graph_builder.add_node(\"document_qa\", document_qa)    # Sonnet 4\n",
    "        graph_builder.add_node(\"general_qa\", general_qa)      # Sonnet 4 + 웹 툴\n",
    "        graph_builder.add_node(\"tools\", tool_node)\n",
    "        \n",
    "        # 기본 엣지들\n",
    "        graph_builder.add_edge(START, \"router\")\n",
    "        \n",
    "        # 라우터에서 분기\n",
    "        graph_builder.add_conditional_edges(\n",
    "            \"router\",\n",
    "            route_by_category,\n",
    "            {\n",
    "                \"document_qa\": \"query_transform\",  # document → query_transform → retrieve → document_qa\n",
    "                \"general_qa\": \"general_qa\",     # general → general_qa\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        # Document 경로: query_transform → retrieve → document_qa → END (Sonnet 4)\n",
    "        graph_builder.add_edge(\"query_transform\", \"retrieve\")\n",
    "        graph_builder.add_edge(\"retrieve\", \"document_qa\")\n",
    "        graph_builder.add_edge(\"document_qa\", END)\n",
    "        \n",
    "        # General 경로: general_qa → (필요시 웹 툴) → END (Sonnet 4)\n",
    "        graph_builder.add_conditional_edges(\n",
    "            \"general_qa\", \n",
    "            tools_condition,\n",
    "            {\n",
    "                \"tools\": \"tools\",     # 웹 툴 호출 시\n",
    "                \"__end__\": END        # 툴 호출 없으면 종료\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # 웹 툴 실행 후 다시 general_qa로 돌아가서 최종 응답\n",
    "        graph_builder.add_edge(\"tools\", \"general_qa\")\n",
    "        \n",
    "        # 4. 그래프 컴파일\n",
    "        graph = graph_builder.compile().with_config(\n",
    "            config={\"callbacks\": [langfuse_handler]}\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Sonnet 4 단일 모델 시스템 그래프 구성 완료!\")\n",
    "        \n",
    "        # 5. 대화 히스토리 초기화\n",
    "        global conversation_history\n",
    "        conversation_history = []\n",
    "        print(\"✅ 대화 히스토리 초기화 완료!\")\n",
    "        \n",
    "        print(\"\\n📋 그래프 구조:\")\n",
    "        print(\"🚀 라우터: Claude Sonnet 4 - 쿼리 분류\")\n",
    "        print(\"📄 Document 질문: router → query_transform → retrieve → document_qa → END (Sonnet 4)\")\n",
    "        print(\"💭 General 질문: router → general_qa → (필요시 웹 툴) → END (Sonnet 4)\")\n",
    "        \n",
    "        print(\"\\n🎯 모델 사용 현황:\")\n",
    "        print(\"- 모든 작업: Claude Sonnet 4 (최고 성능)\")\n",
    "        print(\"- 쿼리 분류: Claude Sonnet 4\")\n",
    "        print(\"- 문서 QA: Claude Sonnet 4\") \n",
    "        print(\"- 일반 QA + 웹 검색: Claude Sonnet 4\")\n",
    "        \n",
    "        # 6. 그래프 시각화 시도\n",
    "        try:\n",
    "            print(\"\\n그래프 시각화 시도 중...\")\n",
    "            from IPython.display import Image, display\n",
    "            display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "            print(\"그래프 시각화 완료!\")\n",
    "        except Exception as e:\n",
    "            print(f\"그래프 시각화 실패: {e}\")\n",
    "        \n",
    "        # 7. 인터랙티브 채팅 시작\n",
    "        interactive_chat()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"초기화 중 오류 발생: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "779f005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG 컴포넌트 초기화 중...\n",
      "문서 로딩 중...\n",
      "문서 로딩 완료: 40 페이지\n",
      "문서 청킹 중...\n",
      "청킹 완료: 80 청크\n",
      "임베딩 모델 로딩 중...\n",
      "사용 중인 디바이스: mps\n",
      "📏 임베딩 차원 확인 중...\n",
      "✅ 임베딩 차원: 1024\n",
      "🗄️ PGVector 연결 설정 중...\n",
      "🔌 PostgreSQL 연결 테스트 중...\n",
      "❌ PGVector 연결 실패: name 'psycopg2' is not defined\n",
      "💡 PostgreSQL이 실행 중인지 확인하세요:\n",
      "  - brew services start postgresql@15\n",
      "  - 또는 docker run -d --name pgvector-db -p 5432:5432 pgvector/pgvector:pg16\n",
      "초기화 중 오류 발생: name 'psycopg2' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/4n/tjmm0jpn36jdkkfvpw1g79zw0000gn/T/ipykernel_26308/4263156414.py\", line 124, in main\n",
      "    rag_components = initialize_rag_components()\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/4n/tjmm0jpn36jdkkfvpw1g79zw0000gn/T/ipykernel_26308/3533317175.py\", line 70, in initialize_rag_components\n",
      "    conn = psycopg2.connect(CONNECTION_STRING)\n",
      "           ^^^^^^^^\n",
      "NameError: name 'psycopg2' is not defined\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1a8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bf61c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
