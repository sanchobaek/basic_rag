{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2004ba21",
   "metadata": {},
   "source": [
    "RAG - Loader(UpstageDocumentParseLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e37f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 LangChain 라이브러리\n",
    "!pip install langchain langchain-core langchain-community\n",
    "\n",
    "# LLM 연결을 위한 라이브러리 (Claude 사용)\n",
    "!pip install langchain-anthropic\n",
    "\n",
    "# 임베딩 및 벡터 데이터베이스\n",
    "!pip install sentence-transformers faiss-cpu\n",
    "\n",
    "# ReAct 에이전트 관련 라이브러리\n",
    "!pip install langchain-experimental\n",
    "\n",
    "# 환경 변수 관리\n",
    "!pip install python-dotenv\n",
    "\n",
    "# Upstage 문서 파서 (기존 코드에서 사용)\n",
    "!pip install langchain-upstage\n",
    "\n",
    "# HuggingFace 임베딩 (기존 코드에서 사용)\n",
    "!pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import UpstageDocumentParseLoader\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "file_path = \"./test_modified.pdf\"\n",
    "\n",
    "loader = UpstageDocumentParseLoader(\n",
    "    file_path,\n",
    "    split=\"page\",  # 페이지별로 분할\n",
    "    output_format=\"markdown\",  # 텍스트 형태로 출력\n",
    "    ocr=\"auto\",  # 자동 OCR 사용\n",
    "    coordinates=True,  # 좌표 정보 포함\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59fa30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(docs[21].page_content)\n",
    "# print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d44f9b7",
   "metadata": {},
   "source": [
    "Rag - Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfdbda95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#  문서 자르기 (AI가 읽기 쉬운 크기로 쪼개기)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)\n",
    "\n",
    "# 문서 분할 실행\n",
    "docs_splitter = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8036f25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (5.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from sentence_transformers) (4.53.2)\n",
      "Requirement already satisfied: tqdm in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from sentence_transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from sentence_transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from sentence_transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from sentence_transformers) (0.33.4)\n",
      "Requirement already satisfied: Pillow in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from sentence_transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from sentence_transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.7.9)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/baegjonghun/.pyenv/versions/3.11.10/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Using cached tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-upstage 0.6.0 requires tokenizers<0.20.0,>=0.19.1, but you have tokenizers 0.21.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.21.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3aab1",
   "metadata": {},
   "source": [
    "Rag - Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78aeb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# 기존 임베딩 그대로 사용\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-large-instruct\",\n",
    "    model_kwargs={\"device\": \"mps\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52858f3",
   "metadata": {},
   "source": [
    "Rag - Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f2ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG - Vector Store\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=docs_splitter,\n",
    "    embedding=hf_embeddings,  # 커스텀 임베딩 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647a517",
   "metadata": {},
   "source": [
    "Rag - retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27a3da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG - retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5},\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",  # 유사도 검색\n",
    "    search_kwargs={\"k\": 5},  # 상위 5개 결과 반환\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c541ae",
   "metadata": {},
   "source": [
    "Rag- retriever to tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.tools import Tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 필요한 임포트 추가\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_anthropic import ChatAnthropic  # Claude 사용 시\n",
    "# from langchain_aws import BedrockChat  # AWS Bedrock 사용 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e9565d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🤖 RAG 에이전트 시작\n",
      "💡 '종료' 입력 시 대화를 끝냅니다.\n",
      "============================================================\n",
      "🤖 AI: \n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"죄송합니다만, 제가 가진 정보로는 특정 과자를 추천해드리기 어렵습니다. 과자 추천은 개인의 취향과 선호도에 따라 크게 달라질 수 있기 때문입니다. 하지만 일반적으로 인기 있는 과자 몇 가지를 말씀드릴 수 있습니다:\n",
      "\n",
      "1. 초코파이\n",
      "2. 새우깡\n",
      "3. 꼬깔콘\n",
      "4. 오레오\n",
      "5. 프링글스\n",
      "\n",
      "이 외에도 다양한 맛있는 과자들이 있습니다. 개인의 취향에 따라 달콤한 과자, 짭짤한 과자, 바삭한 과자 등을 선택하실 수 있습니다. 또한 최근에는 건강에 좋은 재료를 사용한 과자들도 많이 출시되고 있으니 참고하시면 좋을 것 같습니다.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "죄송합니다만, 제가 가진 정보로는 특정 과자를 추천해드리기 어렵습니다. 과자 추천은 개인의 취향과 선호도에 따라 크게 달라질 수 있기 때문입니다. 하지만 일반적으로 인기 있는 과자 몇 가지를 말씀드릴 수 있습니다:\n",
      "\n",
      "1. 초코파이\n",
      "2. 새우깡\n",
      "3. 꼬깔콘\n",
      "4. 오레오\n",
      "5. 프링글스\n",
      "\n",
      "이 외에도 다양한 맛있는 과자들이 있습니다. 개인의 취향에 따라 달콤한 과자, 짭짤한 과자, 바삭한 과자 등을 선택하실 수 있습니다. 또한 최근에는 건강에 좋은 재료를 사용한 과자들도 많이 출시되고 있으니 참고하시면 좋을 것 같습니다.\n",
      "🤖 AI: \n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m아주대학교 건축학과의 수시 모집 인원을 확인하기 위해 문서를 검색해보겠습니다.\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"document_search\",\n",
      "    \"action_input\": \"아주대학교 건축학과 수시 모집 인원\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[문서 1]\n",
      "2026학년도 # 아주대학교 입학전형안내 본 입학전형 시행계획은 관계 법령 개정, 대학구조개혁을 위한 학사조직 개편,\n",
      "관련 위원회 심의결과 등에 따라 변경될 수 있습니다. 반드시 각 모집시기별 모집요강을 확인하시기 바랍니다. 16499 경기도 수원시 영통구 월드컵로 206 아주대학교 율곡관 102호 입학처\n",
      "TEL. 031) 219-3200~3202 FAX. 031) 213-5174 www.iajou.ac.kr\n",
      "\n",
      "[문서 2]\n",
      "# 법학전문대학원 ![image](/image/placeholder)\n",
      " # 11위 ![image](/image/placeholder)\n",
      " 제 14회 변호사시험 합격률 25개\n",
      "로스쿨 중 전국 11위 지속적인 합격률과\n",
      "진로 성과로 증명된\n",
      "실력 중심 교육체계 ![image](/image/placeholder)\n",
      " 541명 합격\n",
      "전체 졸업생 613명 중\n",
      "541명 합격 # 93.8% 법무법인, 국가기관 등\n",
      "전체 취업률 93.8% # 간호대학 # AJOU\n",
      "UNIVERSITY ![image](/image/placeholder)\n",
      " 국가고시\n",
      "전원 합격의 전통과\n",
      "실습 중심 교육의\n",
      "모범 사례 100%\n",
      "2003~2025년 연속\n",
      "간호사 국가고시 100% 합격 ![image](/image/placeholder)\n",
      " 6억원 2020년 간호대학 실습교육 지원사업\n",
      "보건복지부 6억원 지원 우수사례기관 2020년 간호대학 실습교육 지원사업\n",
      "우수사례기관 선정 2026학년도 아주대학교 입학전형안내 13\n",
      "\n",
      "[문서 3]\n",
      "| 수시 | 학생부종합 (ACE전형) | 의학과 | 국어, 수학(선택과목 제한 없음), 영어, 탐구(과탐, 사탐 중 2개 과목 평균) 등급 합 6이내 |\n",
      "| 수시 | 학생부종합 (ACE전형) | 약학과 | 국어, 수학(선택과목 제한 없음), 영어, 탐구(과탐, 사탐 중 2개 과목 평균) 중 3개 영역 등급 합 5이내 |\n",
      "| 수시 | 논술 (논술우수자전형) | 의학과 | 국어, 수학(선택과목 제한 없음), 영어, 탐구(과탐, 사탐 중 2개 과목 평균) 등급 합 6이내 |\n",
      "| 수시 | 논술 (논술우수자전형) | 약학과 | 국어, 수학(선택과목 제한 없음), 영어, 탐구(과탐, 사탐 중 2개 과목 평균) 중 3개 영역 등급 합 5이내 |\n",
      "| 정시 | 수능(국방IT우수인재2전형) | 수능(국방IT우수인재2전형) | 수학(선택과목 제한 없음), 탐구(과탐, 사탐 중 2개 과목 평균) 등급 합 6이내 |\n",
      " ※ 수능최저학력기준은 2026학년도 대학수학능력시험 성적(등급)으로 반영하며, 탐구영역은 직탐을 포함할 수 없음 2026학년도 아주대학교 입학전형안내 29\n",
      "\n",
      "[문서 4]\n",
      "| 학생부종합 (국방IT 우수인재1전형) (정원외) | ② 원서접수 마감일 기준 대한민국 국적인 자(이중국적자는 지원할 수 없음) ③ 친권자 동의 및 본인이 재정보증보험에 가입 가능한 자 ※ 신용불량 등의 사유로 본인이 재정보증보험에 가입 제한 시 지원불가 ④ 입학 후 당해 학년도 최초 학기 수강이 가능한 자 | ② 원서접수 마감일 기준 대한민국 국적인 자(이중국적자는 지원할 수 없음) ③ 친권자 동의 및 본인이 재정보증보험에 가입 가능한 자 ※ 신용불량 등의 사유로 본인이 재정보증보험에 가입 제한 시 지원불가 ④ 입학 후 당해 학년도 최초 학기 수강이 가능한 자 | ② 원서접수 마감일 기준 대한민국 국적인 자(이중국적자는 지원할 수 없음) ③ 친권자 동의 및 본인이 재정보증보험에 가입 가능한 자 ※ 신용불량 등의 사유로 본인이 재정보증보험에 가입 제한 시 지원불가 ④ 입학 후 당해 학년도 최초 학기 수강이 가능한 자 | ② 원서접수 마감일 기준 대한민국 국적인 자(이중국적자는 지원할 수 없음) ③ 친권자 동의 및 본인이 재정보증보험에 가입 가능한 자 ※ 신용불량 등의 사유로 본인이 재정보증보험에 가입 제한 시 지원불가 ④ 입학 후 당해 학년도 최초 학기 수강이 가능한 자 |\n",
      " 2026학년도 아주대학교 입학전형안내 35\n",
      "\n",
      "[문서 5]\n",
      "# 의과대학 증진을 위한\n",
      "최첨단 인프라 # 신관 경기도 단일 병원 최대 규모인 1,465병상\n",
      "지하 3층 지상 15층, 17,000평 규모 ![image](/image/placeholder)\n",
      " ![image](/image/placeholder)\n",
      " ![image](/image/placeholder)\n",
      " 평택 아주대 병원\n",
      "500병상 규모의 첨단 스마트\n",
      "인텔리전트 종합병원\n",
      "2030년 준공 예정, 22,500평 규모 ![image](/image/placeholder)\n",
      " # 교육 연구동 글로벌 의료 인재 양성을 비롯한\n",
      "혁신적인 연구 인프라 지하 1층 지상 10층, 4,600평 규모 ![image](/image/placeholder)\n",
      " ![image](/image/placeholder)\n",
      " 2026학년도 아주대학교 입학전형안내 15\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"죄송합니다만, 제공된 문서에서 아주대학교 건축학과의 수시 모집 인원에 대한 구체적인 정보를 찾을 수 없었습니다. 문서에는 주로 의학과, 약학과, 간호대학, 법학전문대학원 등에 대한 정보만 포함되어 있었고, 건축학과에 대한 언급은 없었습니다. 정확한 정보를 얻기 위해서는 아주대학교 입학처 홈페이지나 최신 모집요강을 직접 확인하시는 것이 좋을 것 같습니다.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "죄송합니다만, 제공된 문서에서 아주대학교 건축학과의 수시 모집 인원에 대한 구체적인 정보를 찾을 수 없었습니다. 문서에는 주로 의학과, 약학과, 간호대학, 법학전문대학원 등에 대한 정보만 포함되어 있었고, 건축학과에 대한 언급은 없었습니다. 정확한 정보를 얻기 위해서는 아주대학교 입학처 홈페이지나 최신 모집요강을 직접 확인하시는 것이 좋을 것 같습니다.\n",
      "👋 채팅을 종료합니다!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Retriever를 직접 Tool로 래핑하는 함수\n",
    "def search_documents(query: str) -> str:\n",
    "    \"\"\"문서 검색 도구 함수\"\"\"\n",
    "    # 관련 문서 검색\n",
    "    docs = retriever.invoke(query)\n",
    "    \n",
    "    # 검색 결과가 없는 경우\n",
    "    if not docs:\n",
    "        return \"검색 결과가 없습니다.\"\n",
    "    \n",
    "    # 검색 결과 포맷팅\n",
    "    formatted_results = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        # 각 문서 내용 추가\n",
    "        formatted_results.append(f\"[문서 {i}]\\n{doc.page_content}\\n\")\n",
    "    \n",
    "    return \"\\n\".join(formatted_results)\n",
    "\n",
    "# Tool 객체 생성\n",
    "document_search_tool = Tool(\n",
    "    name=\"document_search\",\n",
    "    description=\"문서 내용을 검색할 때 사용하는 도구입니다. 제공된 PDF 문서 내에서 관련 정보를 찾아 제공합니다.\",\n",
    "    func=search_documents\n",
    ")\n",
    "\n",
    "# 에이전트 생성에 필요한 Tool 리스트\n",
    "tools = [document_search_tool]\n",
    "\n",
    "# LLM 설정\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0)\n",
    "\n",
    "\n",
    "# 에이전트 프롬프트 템플릿 생성\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"너는 친절한 한국어 AI 비서야. 사용자의 질문에 답변하기 위해 문서 검색 도구를 사용할 수 있어.\n",
    "    \n",
    "    가장 중요한 규칙: 절대로 문서에 없는 내용을 답변에 포함하지 마세요. \n",
    "    문서에서 관련 정보를 찾지 못했다면 \"죄송합니다만, 문서에서 해당 정보를 찾을 수 없습니다.\"라고만 답변하세요.\n",
    "    \n",
    "    항상 다음 과정을 따라야 해:\n",
    "    1. 사용자의 질문을 분석해서 문서 검색이 필요한지 판단해\n",
    "    2. 필요하다면 document_search 도구를 사용해 관련 정보를 찾아\n",
    "    3. 검색 결과를 기반으로 한국어로 답변을 작성해\n",
    "    4. 검색 결과에 관련 정보가 없다면 \"죄송합니다만, 문서에서 해당 정보를 찾을 수 없습니다.\"라고 답변해\n",
    "    5. 절대로 너의 일반 지식을 사용하여 문서에 없는 내용을 답변하지 마\n",
    "    \n",
    "    항상 한국어로 답변하고, 정확한 정보만 제공하도록 해.\n",
    "    \"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "# 에이전트 초기화\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,  # 대화형 에이전트 사용\n",
    "    verbose=True,  # 실행 과정 출력\n",
    "    max_iterations=3,  # 최대 반복 횟수\n",
    "    handle_parsing_errors=True,  # 파싱 오류 처리\n",
    "    early_stopping_method=\"generate\",  # 조기 종료 방법\n",
    "    prompt=agent_prompt  # 커스텀 프롬프트 사용\n",
    ")\n",
    "\n",
    "# 에이전트 실행 함수\n",
    "def run_agent_with_history(query, chat_history=[]):\n",
    "    \"\"\"에이전트를 실행하여 질문에 답변\"\"\"\n",
    "    try:\n",
    "        response = agent.invoke({\n",
    "            \"input\": query,\n",
    "            \"chat_history\": chat_history\n",
    "        })\n",
    "        # 대화 히스토리 업데이트를 위한 출력 형식 맞추기\n",
    "        return response[\"output\"]\n",
    "    except Exception as e:\n",
    "        return f\"에이전트 실행 중 오류 발생: {str(e)}\"\n",
    "\n",
    "# 대화 히스토리 관리\n",
    "agent_chat_history = []\n",
    "\n",
    "# 대화형 인터페이스\n",
    "def interactive_agent_chat():\n",
    "    \"\"\"대화형 에이전트 인터페이스\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🤖 RAG 에이전트 시작\")\n",
    "    print(\"💡 '종료' 입력 시 대화를 끝냅니다.\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\"\\n🙋 사용자: \").strip()\n",
    "\n",
    "                if not user_input:\n",
    "                    print(\"❗ 메시지를 입력해주세요.\")\n",
    "                    continue\n",
    "\n",
    "                if user_input.lower() == \"종료\":\n",
    "                    print(\"👋 채팅을 종료합니다!\")\n",
    "                    break\n",
    "\n",
    "                print(\"🤖 AI: \", end=\"\")\n",
    "                response = run_agent_with_history(user_input, agent_chat_history)\n",
    "                print(response)\n",
    "\n",
    "                # 에이전트 히스토리 업데이트\n",
    "                agent_chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "                agent_chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n채팅을 종료합니다!\")\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        # 히스토리 초기화\n",
    "        agent_chat_history.clear()\n",
    "\n",
    "# 메인 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_agent_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
